{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "079bf8854a4255688941af2bd371b587b1f25737b4330b6346f5799c6c867e75"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"380\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Exploratory Data Analysis Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **30** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this module you get to work with the cleaned dataset from the previous module.\n\nIn this assignment you will perform the task of exploratory data analysis.\nYou will find out the distribution of data, presence of outliers and also determine the correlation between different columns in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab you will perform the following:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "-   Identify the distribution of data in the dataset.\n\n-   Identify outliers in the dataset.\n\n-   Remove outliers from the dataset.\n\n-   Identify correlation between features in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "* * *\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Hands on Lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import the pandas module.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#pip install seaborn\n\nimport pandas as pd\n#import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import gaussian_kde",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-6cbf8d3c5627>:3: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Load the dataset into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m2_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"m2_survey_data.csv\")\nfile_name=\"m2_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Utilize the Pandas method read_csv() to load the data into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m2_survey_data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Distribution\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Determine how the data is distributed\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The column `ConvertedComp` contains Salary converted to annual USD salaries using the exchange rate on 2019-02-01.\n\nThis assumes 12 working months and 50 working weeks.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Plot the distribution curve for the column `ConvertedComp`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\ncleaned_converted_comp = df['ConvertedComp'].dropna().replace([np.inf, -np.inf], np.nan).dropna()\nplt.figure(figsize=(10, 6))\n\n# Plot histogram\nplt.hist(cleaned_converted_comp, bins=30, alpha=0.6, color='blue', edgecolor='black', density=True)\n\n# Calculate KDE\nkde = gaussian_kde(cleaned_converted_comp)\nx = np.linspace(cleaned_converted_comp.min(), cleaned_converted_comp.max(), 100)\nplt.plot(x, kde(x), color='red')\n\nplt.title('Distribution of Converted Compensation', fontsize=16)\nplt.xlabel('Converted Compensation (USD)', fontsize=14)\nplt.ylabel('Density', fontsize=14)\n\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Plot the histogram for the column `ConvertedComp`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\n# Drop missing values in the 'ConvertedComp' column\ndf['ConvertedComp'].dropna()\n\n# Plot the histogram\nplt.figure(figsize=(10, 6))\nplt.hist(df['ConvertedComp'], bins=30, color='skyblue')\n\n# Add titles and labels\nplt.title('Histogram of Converted Compensation', fontsize=16)\nplt.xlabel('Converted Compensation (USD)', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\n\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "What is the median of the column `ConvertedComp`?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\ndf['ConvertedComp'].median()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "How many responders identified themselves only as a **Man**?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\ndf[df['Gender'] == 'Man'].shape[0]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Find out the  median ConvertedComp of responders identified themselves only as a **Woman**?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Filter the dataframe for respondents who identified themselves as 'Woman'\nwomen = df[df['Gender'] == 'Woman']\n\n# Calculate the median of 'ConvertedComp' for these respondents\nmedian = women['ConvertedComp'].median()\n\nmedian",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Give the five number summary for the column `Age`?\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Double click here for hint**.\n\n<!--\nmin,q1,median,q3,max of a column are its five number summary.\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Calculate the five-number summary for the 'Age' column\nmin = df['Age'].min()\nq1 = df['Age'].quantile(0.25)\nmedian = df['Age'].median()\nq3 = df['Age'].quantile(0.75)\nmax = df['Age'].max()\n\n# Print the results\nprint(f\"Five-number summary for Age:\")\nprint(f\"Minimum: {min}\")\nprint(f\"First Quartile (Q1): {q1}\")\nprint(f\"Median (Q2): {median}\")\nprint(f\"Third Quartile (Q3): {q3}\")\nprint(f\"Maximum: {max}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Plot a histogram of the column `Age`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\n# Plot the histogram for the 'Age' column\nplt.figure(figsize=(8, 6))\nplt.hist(df['Age'].dropna(), bins=20, edgecolor='black', color='skyblue')\nplt.title('Distribution of Age', fontsize=16)\nplt.xlabel('Age', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.grid(True)\n\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Outliers\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Finding outliers\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find out if outliers exist in the column `ConvertedComp` using a box plot?\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\n# Create a box plot for the 'ConvertedComp' column\nplt.figure(figsize=(10, 6))\nplt.boxplot(df['ConvertedComp'].dropna(), patch_artist=True, boxprops=dict(facecolor='lightblue'))\n\n# Add titles and labels\nplt.title('Box Plot of Converted Compensation', fontsize=16)\nplt.xlabel('Converted Compensation (USD)', fontsize=12)\n\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Find out the Inter Quartile Range for the column `ConvertedComp`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Calculate Q1 (25th percentile) and Q3 (75th percentile)\nq1 = df['ConvertedComp'].quantile(0.25)\nq3 = df['ConvertedComp'].quantile(0.75)\n\n# Calculate the Interquartile Range (IQR)\niqr = q3 - q1\niqr",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Find out the upper and lower bounds.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n\n# Calculate the lower and upper bounds\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\n# Print the results\nprint(f\"The lower bound for ConvertedComp is: {lower_bound}\")\nprint(f\"The upper bound for ConvertedComp is: {upper_bound}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Identify how many outliers are there in the `ConvertedComp` column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Count the number of outliers\ndf[(df['ConvertedComp'] < lower_bound) | (df['ConvertedComp'] > upper_bound)].shape[0]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Create a new dataframe by removing the outliers from the `ConvertedComp` column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Create a new dataframe by removing outliers\ndf_no_outliers = df[(df['ConvertedComp'] >= lower_bound) & (df['ConvertedComp'] <= upper_bound)]\n\n# Print the shape of the new dataframe to verify the removal of outliers\nprint(f\"The shape of the original dataframe: {df.shape}\")\nprint(f\"The shape of the new dataframe without outliers: {df_no_outliers.shape}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Correlation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Finding correlation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the correlation between `Age` and all other numerical columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\n# Filter the DataFrame to only include numeric columns\nnumeric_df = df.select_dtypes(include=['float64', 'int64'])\n\n# Calculate the correlation matrix\ncorrelation_matrix = numeric_df.corr()\n\n# Get the correlation values for the 'Age' column\nage_correlation = correlation_matrix['Age']\n\n# Display the correlation matrix and age correlation\nprint(correlation_matrix)\nprint(age_correlation)\n\n#Overall, the correlations in the matrix indicate mostly weak relationships among the variables.\n#The strongest correlation in the matrix is between ConvertedComp and Age, but it’s still relatively weak. This suggests that while age might have a slight impact on compensation, other factors likely play a more significant role. The relationships between compensation and work hours are also weak, indicating that the amount of time worked does not strongly influence the compensation rates.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ramesh Sannareddy\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Rav Ahuja\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n",
      "metadata": {}
    }
  ]
}